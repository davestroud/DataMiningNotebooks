{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Grand Poobah Classification Notebook\n",
    "In this notebook we will cover uses of scikit-learn for many different purposes including:\n",
    "- Cross Validation and metrics for scoring (including ROC and confusion matrices)\n",
    "- Pipelines\n",
    "- Common (nonlinear model) Classification:\n",
    " - K-Nearest Neighbors\n",
    " - Naive Bayes\n",
    " - Decision Trees\n",
    "- Bagging (Random Forests)\n",
    "- Boosting (Gradient of Error)\n",
    "- Statistical Comparison Questions\n",
    "\n",
    "We will look at some of the advanced features of scikit and look at many different ways of going about using the system to its fullest potential.\n",
    "\n",
    "- http://en.wikipedia.org/wiki/Grand_Poobah\n",
    "\n",
    "For this assignment we will use the LFW faces dataset and try to perform recognition of different individual's faces with several different classifiers. \n",
    "\n",
    "You can look up the dataset here:\n",
    " - http://vis-www.cs.umass.edu/lfw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading LFW metadata: https://ndownloader.figshare.com/files/5976012\n",
      "Downloading LFW metadata: https://ndownloader.figshare.com/files/5976009\n",
      "Downloading LFW metadata: https://ndownloader.figshare.com/files/5976006\n",
      "Downloading LFW data (~200MB): https://ndownloader.figshare.com/files/5976015\n"
     ]
    }
   ],
   "source": [
    "# fetch the images for the dataset\n",
    "# this will take a long time the first run because it needs to download\n",
    "# after the first time, the dataset will be save to your disk (in sklearn package somewhere) \n",
    "# if this does not run, you may need additional libraries installed on your system \n",
    "# (you will need to figure out which ones!!)\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "\n",
    "# only load people that have N or more examples in the dataset\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=20, resize=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataset: (3023, 1850)\n",
      "Number of unique classes: 62\n"
     ]
    }
   ],
   "source": [
    "print ('Size of the dataset:', lfw_people.data.shape)\n",
    "print ('Number of unique classes:', len(lfw_people.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
